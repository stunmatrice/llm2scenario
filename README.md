# 一.概述
## 1.项目任务：
- 从一段文本生成carla中的仿真场景模拟
- 一般是针对一个非常有代表性的安全关键场景(其他别称长尾场景)
- 通过代理控制每个交通实体的运动以达到文本描述和实体运动的一致性


## 2.技术思路：
- 初始化场景 - 运行角色代理 - 传感器数据捕捉 - 场景帧数据写入
- 文本蕴含场景发生的位置，对应到地图/关卡 中的某个具体范围
- 文本中蕴含各种主要交互实体在时间和空间上关系，具体来说可以表述为事件，行为 


## 3.前置知识：
- 自动驾驶仿真系统：自动驾驶仿真系统是建立在 游戏引擎/仿真引擎/视景仿真系统/虚拟现实系统之上的应用系统，自动驾驶仿真系统是当前 工业界正在加速构建的重要基础设施。特别是 目前端到端自动驾驶技术正在快速发展。
- 端到端自动驾驶技术 相对于基于规则的自动驾驶技术在技术架构上有 很大的变化，从感知到决策规划，都在统一的架构(如 Transformer)之下，可以进行联合优化。
- 端到端，从感知到规划，其中的架构设计是多样的，比较典型的工作包含：BEVFormer，UniAD，VAD，DriveTransformer。
- 可以看到这些工作都以Transformer为核心架构，来融合多种传感器数据输入。
- 感知-决策-规划-控制，是自动驾驶中典型的模块，其中感知又有目标检测，识别，跟踪，预测，分割等重要任务，这些任务都需要大量的标注数据，特别地，像跟踪预测等任务还需跨帧标注（4d标注）。体现在技术上，Transformer的输入中会加入历史BEV特征序列。
- 在仿真环境中获取 自动驾驶仿真数据 是一个不错的技术方案，其中重要的原因是仿真世界中对数据的标注是简单而精确地。在真实的自动驾驶数据中，还需要其他技术手段，如多模态大模型。或者使用昂贵的人工标注。随着渲染和仿真技术的发展，从仿真环境中获取以假乱真的图像是非常可能的。
- 前沿：自动驾驶技术的前沿现在是在多模态领域，关键词包括VLM、VLA，融入语言模态的信息来增加决策的可解释性，给自动驾驶加一个会思考会推理的大脑。


## 4.技术难点：
- 本工作希望通过文本描述来简化长尾交通场景的生成，目前交通场景的生成已有的方案如：1.手动编写OpenScenario，Scenic 2.使用大模型生成OpenScenario，Scenic 3.声明式描述每个实体的行为序列，用大模型处理，转换成行为树，再调用底层的行为实现
- 技术难点1: 提供一种结构化的文本形式，这种形式可以容易被仿真系统执行，并且能被视为 元操作，可以以组合的方式构建更复杂的个体行为，目前找到的结构是行为树，在实现的过程中，对行为树的使用进行了限制。一个重要的原因的是行为树需要保持对行为的状态的判断，以进行状态的切换，大部分情况是涉及到个体之间的交互的时候，如ego前方靠近npc，需要切换到变道/减速。这种交互逻辑使用基于规则的方式是繁琐的，去掉这种条件的判断，可以理解为个体行为之间没有耦合，大大简化了系统的实现，很方便将个体行为进行原子封装。被上层声明式调用。
- 技术难点2：提供对生成过程的量化评估以及自动化迭代改进。




# 二. 问题分解
## 1.场景初始化：描述的场景对应的地图，场景发生的地图范围 
- 场景的地图，包含一个UE关卡，呈现交通场景的视觉内容
- 一个OpenDRIVE道路描述，在单独的路径，和关卡一一对应，联合仿真共享文件
- 如何确定这个场景的初始位置，使用基于文本相似度搜索 是不错的方法，需要将地图坐标位置 和 文本关联起来，将文本转换成向量，存入向量数据库，以供后面检索
- 


## 2.角色出生：地图范围中的角色创建
- 包含角色的类型id，id映射到引擎的角色蓝图资源
- 包含角色的出生位置，指定角色的全局变换
- 



# 三. 进展与后续
## 1.目前可以以文本的形式描述每个实体的行为，文本描述如下
```
The ego vehicle goes to target0,then target1, then target2, then target3, then target4 with speed of 20 km/h,
npc vehicles 1 goes to target0,then target1, then target2, then target3, then target4 with speed of 20 km/h, 
npc vehicles 2 accelerates to 20km/h in 2s, then keep in lane in 20km/h for 20s,
npc vehicles 3 accelerates to 20km/h in 2s, then keep in lane in 20km/h for 20s,
npc vehicles 4 goes to target0,then target1, then target2 with speed of 20 km/h
```
已经实现了对应的Agent，将改形式的文本转换成carla中每个实体的运动片段
运行方式
```
// server端，启动carla仿真器，启动大模型API服务
// 在vscode通过 ssh登录
fengyunzhou@162.105.90.212
graphics

// 说明文档路径在 /home/fengyunzhou/mark.txt


// client端，在本地安装UE carla fork
// 安装carla 客户端
// 将本仓库克隆到 carla/PythonAPI/carla


// 运行客户端需要传递正确的 服务器地址和端口 作为参数

```


## 2.后续的工作是自动化来生成以上文本片段，以实现全流程的自动化
- 最近有一种趋势，是使用交通场景视频数据，通过一个 流程将视频中呈现的交通场景 转换成仿真中的结构。第一阶段的工作已经可以支撑这个数据转换。
- 建立起一种可以自动评估，自动迭代的系统 会是一个非常不错的工作。
- 要做成这个工作核心还是看VLM的能力如何。如何使用当前有限的资源，自动化迭代优化，只通过有限的
- 这个工作的输入部分可以不仅是一段文本，也可以是一旦视频，使用多模态大模型，来提取视频中的信息，并输出为文本，将输出严格限制为第一步的形式，可以作为一个更为完善的学术工作
- 


